{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefa2802",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "## Digit Classification Model\n",
    "\n",
    "In this Section :-\n",
    "- Loading the dataset.\n",
    "- Splitting the dataset into Training and Validation Set.\n",
    "- Preprocessing the dataset.\n",
    "- Model building and Training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7a4ce",
   "metadata": {},
   "source": [
    "### Loading the dataset.\n",
    "The dataset of images is used for building a suitable model to classify numbers in an image. Data is then specified as features(the image) and labels(the tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc1293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Importing required libraries #####\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0131414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = os.listdir(r\"D:\\Learn to Improve\\My Kaggle Journey\\End-to-end Projects\\Sudoku Solver using OpenCV and ML\\Digits\")\n",
    "\n",
    "data_X = []\n",
    "data_y = []\n",
    "\n",
    "data_classes = len(data)  # This is no. of sub-directories in Digits directory. i.e. 10\n",
    "\n",
    "for i in range(0, data_classes):\n",
    "    data_list = os.listdir(r\"D:\\Learn to Improve\\My Kaggle Journey\\End-to-end Projects\\Sudoku Solver using OpenCV and ML\\Digits\" + \"/\" + str(i))\n",
    "    \n",
    "    for j in data_list:\n",
    "        # Reading all the images using cv2.\n",
    "        pic = cv2.imread(r\"D:\\Learn to Improve\\My Kaggle Journey\\End-to-end Projects\\Sudoku Solver using OpenCV and ML\\Digits\" + \"/\" + str(i) + \"/\" + str(j))\n",
    "        pic = cv2.resize(pic ,(32, 32))\n",
    "        data_X.append(pic)  # Creating features.\n",
    "        data_y.append(i)\n",
    "                           \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9db30c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints: 10160\n"
     ]
    }
   ],
   "source": [
    "if len(data_X) == len(data_y):\n",
    "    print(f\"Total datapoints: {len(data_X)}\" )\n",
    "    \n",
    "# Labels and images.\n",
    "data_X = np.array(data_X)\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca7143",
   "metadata": {},
   "source": [
    "\n",
    "### Splitting the dataset.\n",
    "1. Splitting the dataset into test, train and validation sets. \n",
    "2. Preprocessing for the features (images) into grayscale, enhancing it with histogram equalization and then normalizing.\n",
    "3. Followed by converting then into a NumPy array. \n",
    "4. Further reshaping the image's array and using data augmentation. \n",
    "5. Preprocessing for the labels involves one-hot encoding the label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d104566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (7721, 32, 32, 3)\n",
      "Validation set shape: (1931, 32, 32, 3)\n",
      "Test set shape: (508, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train, test and validation set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size = 0.05)\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size = 0.2)\n",
    "\n",
    "print(f\"Training set shape: {train_X.shape}\")\n",
    "print(f\"Validation set shape: {valid_X.shape}\")\n",
    "print(f\"Test set shape: {test_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27cce664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the images for the neural net.\n",
    "def Prep(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Making image grayscale for easy preprocessing.\n",
    "    img = cv2.equalizeHist(img) # Histogram equalization to improve contrast.\n",
    "    img = img / 255  # Normalizing.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "396444a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting images into numpy arrays.\n",
    "train_X = np.array(list(map(Prep, train_X)))\n",
    "valid_X = np.array(list(map(Prep, valid_X)))\n",
    "test_X = np.array(list(map(Prep, test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31a5762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the imges.\n",
    "train_X = train_X.reshape(train_X.shape[0], train_X.shape[1], train_X.shape[2], 1)\n",
    "valid_X = valid_X.reshape(valid_X.shape[0], valid_X.shape[1], valid_X.shape[2], 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], test_X.shape[1], test_X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d379e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation (Manipulation of images according to our use)\n",
    "datagen = ImageDataGenerator(width_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
